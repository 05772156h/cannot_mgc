import numpy as np
import torch
from torch import nn
from torch.utils.data import Dataset, DataLoader
from torch.utils.tensorboard import SummaryWriter
import pandas as pd
from sklearn.model_selection import train_test_split

class ArknightsDataset(Dataset):
    def __init__(self, csv_file):
        data = pd.read_csv(csv_file, header=None)
        features = data.iloc[:, :-1].values.astype(np.float32)
        labels = data.iloc[:, -1].map({'L': 0, 'R': 1}).values
        labels = np.where((labels != 0) & (labels != 1), 0, labels).astype(np.int8)

        self.left_counts = np.abs(features[:, :73])
        self.right_counts = np.abs(features[:, 73:])
        self.labels = labels

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, idx):
        return (
            torch.reshape(torch.tensor(self.left_counts[idx]), (1, 73)),
            torch.reshape(torch.tensor(self.right_counts[idx]), (1, 73)),
            torch.tensor(self.labels[idx], dtype=torch.long)
        )

class Cannot(nn.Module):
    def __init__(self):
        super().__init__()
        self.count_to_feat = nn.Linear(73, 64)
        self.friend_feat = nn.MultiheadAttention(64, 8, batch_first=True, dropout=0.2)
        self.enemy_feat = nn.MultiheadAttention(64, 8, batch_first=True, dropout=0.2)
        self.feat_to_win = nn.Sequential(
            nn.Linear(64, 64),
            nn.ReLU(),
            nn.Linear(64, 1),
        )

    def forward(self, left_count, right_count):
        left_feat = self.count_to_feat(left_count)
        right_feat = self.count_to_feat(right_count)

        left_friend_feat, _ = self.friend_feat(
            query=left_feat,
            key=left_feat,
            value=left_feat,
            need_weights=False
        )
        right_friend_feat, _ = self.friend_feat(
            query=right_feat,
            key=right_feat,
            value=right_feat,
            need_weights=False
        )

        left_enemy_feat, _ = self.enemy_feat(
            query=left_feat,
            key=right_feat,
            value=right_feat,
            need_weights=False
        )
        right_enemy_feat, _ = self.enemy_feat(
            query=right_feat,
            key=left_feat,
            value=left_feat,
            need_weights=False
        )

        left_total_feat = left_friend_feat + left_enemy_feat
        right_total_feat = right_friend_feat + right_enemy_feat

        left_win = self.feat_to_win(left_total_feat)
        right_win = self.feat_to_win(right_total_feat)

        delta = torch.zeros(64, 2)
        for i in range(64):
            delta[i][0] = left_win[i][0] - right_win[i][0]
        return delta

def main():
    dataset = ArknightsDataset('arknights.csv')
    train_dataset, test_dataset = train_test_split(
        range(len(dataset)), test_size=0.2, random_state=42
    )

    train_dataloader = DataLoader(
        torch.utils.data.Subset(dataset, train_dataset),
        batch_size=64,
        shuffle=True,
        num_workers=2,
        drop_last=True
    )
    test_dataloader = DataLoader(
        torch.utils.data.Subset(dataset, test_dataset),
        batch_size=64,
        num_workers=2,
        drop_last=True
    )

    train_data_size = len(train_dataloader) * 64
    test_data_size = len(test_dataloader) * 64

    cannot = Cannot()
    cannot = cannot.cuda()

    loss_fn = nn.CrossEntropyLoss()
    loss_fn = loss_fn.cuda()

    learning_rate = 0.001
    optimizer = torch.optim.Adam(cannot.parameters(), lr=learning_rate)

    total_train_step = 0
    total_test_step = 0
    epoch = 100

    writer = SummaryWriter('logs_train_1')

    print('训练数据集的长度为:{}'.format(train_data_size))
    print('测试数据集的长度为:{}'.format(test_data_size))

    best_test_accuracy = 0

    for i in range(epoch):
        print('-------第{}轮训练开始-------'.format(i + 1))

        cannot.train()
        for data in train_dataloader:
            lc, rc, labels = data
            lc, rc, labels = lc.cuda(), rc.cuda(), labels.cuda()
            outputs = cannot(lc, rc)
            outputs = outputs.cuda()
            loss = loss_fn(outputs, labels)

            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            total_train_step += 1
            if total_train_step % 100 == 0:
                print('训练次数:{}，Loss：{}'.format(total_train_step, loss.item()))
                writer.add_scalar('train_loss', loss.item(), total_train_step)

        total_test_loss = 0
        total_accuracy = 0
        cannot.eval()
        with torch.no_grad():
            for data in test_dataloader:
                lc, rc, labels = data
                lc, rc, labels = lc.cuda(), rc.cuda(), labels.cuda()
                outputs = cannot(lc, rc)
                outputs = outputs.cuda()
                loss = loss_fn(outputs, labels)
                total_test_loss += loss.item()
                accuracy = (outputs.argmax(1) == labels).sum()
                total_accuracy += accuracy.item()
                if total_accuracy > best_test_accuracy:
                    best_test_accuracy = total_accuracy
                    torch.save(cannot, 'cannot_mgc_1_best.pth')

        total_test_step += 1
        print('整体测试集上的Loss:{}'.format(total_test_loss))
        print('整体测试集上的Accuracy:{}'.format(total_accuracy / test_data_size))
        writer.add_scalar('test_loss', total_test_loss, total_test_step)
        writer.add_scalar('test_accuracy', total_accuracy / test_data_size, total_test_step)

        torch.save(cannot, 'cannot_mgc_1_{}.pth'.format(i + 1))
        print('模型已保存')

    writer.close()

if __name__ == "__main__":
    main()
